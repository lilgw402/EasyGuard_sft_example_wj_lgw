trainer:
  default_root_dir: null
  default_hdfs_dir: hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/fa_finetune/mfe_8frames
  logger: true
  log_every_n_steps: 50
  benchmark: false
  enable_speedmonitor: true
  enable_versions: false
  detect_anomaly: false
  deterministic: false
  accelerator: gpu
  accelerator_kwargs: { }
  precision: 16
  max_epochs: 6
  max_steps: -1
  limit_train_batches: null
  limit_val_batches: 50
  limit_test_batches: null
  sync_batchnorm: false
  sync_fit_metrics: null
  val_check_interval: [ 500, 1.0 ]
  accumulate_grad_batches: null
  gradient_clip_val: null
  seed: null
  summarize_model_depth: 2
  resume_ckpt_path: null
  callbacks: null
  enable_checkpoint: true
  checkpoint_monitor: val_top1_acc
  checkpoint_mode: max
  dataloader_timeout: -1
  dataloader_retry_limit: 100
  dataloader_retry_persistent_limit: 5
  find_unused_parameters: true
  project_name: null
  experiment_name: null
  enable_trace: false
  reload_dataloaders_every_n_epochs: -1
  strategy: ddp
  enable_qat: false
  qat_kwargs: { }
  optimizer_kwargs:
    optimizer:
      type: torch.optim.AdamW
      params:
        lr: 0.0001
        betas:
          - 0.9
          - 0.999
        eps: 1.0e-06
        weight_decay: 0.01
        correct_bias: true
        correct_bias_eps: false
        bias_correction: true
        adam_w_mode: true
        amsgrad: false
        set_grad_none: true
        momentum: 0.0
        nesterov: false
    scheduler:
      type: torch.optim.lr_scheduler.LinearLR
      total_steps_param_name: total_iters
      warmup_steps_param_name: num_warmup_steps
      params:
        warmup_step_rate: 0.005
        start_factor: 0.3333333333333333
        end_factor: 1.0
        num_cycles: 0.5
        lr_end: 1.0e-07
        power: 1.0
  grad_norm_layers: [ ]
model:
  backbone: ./examples/framealbert/framealbert_finetune/config_backbone/config_backbone.yaml
  class_num: 2
  hidden_dim: 768
  optim: AdamW
  learning_rate: 0.0001
  weight_decay: 0.0001
  lr_schedule: cosine
  warmup_steps_factor: 0.5
  low_lr_prefix: [ ]
#    - backbone.visual
  freeze_prefix: #[ ]
    - backbone.visual
  load_pretrained: hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/fa_pretrain/v1.1/checkpoints/epoch=4-step=230000-val_loss=1.775.ckpt
  # hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/fa_pretrain/v1/checkpoints/epoch=4-step=230000-val_loss=1.483.ckpt
  # hdfs://harunava/home/byte_magellan_va/user/liutingting.kiwi/ckpt/FrameALBERT_v2_2/model_state_epoch_150000.th
  # hdfs://harunava/home/byte_magellan_va/user/liutingting.kiwi/ckpt/FrameALBERT_v4_1/model_state_epoch_20000.th
  prefix_changes: [ ]
  download_files: [ ]
data:
  train_files: hdfs://harunava/home/byte_magellan_va/user/huotianjiao/misleading_multimodal/train/
  train_size: 300000
  val_files: hdfs://harunava/home/byte_magellan_va/user/huotianjiao/misleading_multimodal/validation/
  val_size: 100000
  train_batch_size: 16
  val_batch_size: 16
  num_workers: 4
  text_len: 256
  frame_len: 8
  exp: default
  download_files: [ ]
log_level: INFO
