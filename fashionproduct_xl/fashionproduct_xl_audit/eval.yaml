trainer:
  default_root_dir: null
  default_hdfs_dir: null     # path to save ckpt
  logger: true
  log_every_n_steps: 100                # log frequence
  benchmark: false
  enable_speedmonitor: true
  enable_versions: false
  detect_anomaly: false
  deterministic: false
  accelerator: gpu
  accelerator_kwargs: { }
  precision: fp16
  max_epochs: 5                         # train epoch
  max_steps: -1
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  sync_batchnorm: false
  sync_fit_metrics: null
  val_check_interval: [ 4000, 1.0 ]      # val frequence, [step(int), epoch(float)]
  accumulate_grad_batches: null
  gradient_clip_val: 1.0
  seed: 42
  summarize_model_depth: 3
  resume_ckpt_path: null
  callbacks: null
  enable_checkpoint: false                 # bool or int to set the max num of ckpt files
  checkpoint_monitor: val_top1_acc      # delete ckpt based on monitor
  checkpoint_mode: max                  # min monitor or max monitor, for example min for loss, max for acc or step
  dataloader_timeout: -1
  dataloader_retry_limit: 100
  dataloader_retry_persistent_limit: 5
  find_unused_parameters: true
  project_name: null
  experiment_name: null
  enable_trace: false
  reload_dataloaders_every_n_epochs: -1
  strategy: ddp
  enable_qat: false
  qat_kwargs: { }
  grad_norm_layers: [ ]
model:
  backbone: /mnt/bn/fashionproductxl/weights/fashionproduct_xl_local  # fashionproduct-xl-hr-v1
  class_num: 47
  hidden_dim: 768
  optim: AdamW
  learning_rate: 0.0001
  weight_decay: 0.0001
  lr_schedule: cosine
  warmup_steps_factor: 0.2
  low_lr_prefix: [ ]
#    - backbone
  freeze_prefix: [ ]
  head_num: 5
  use_multihead: true
  load_pretrained: hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_ptm/0610_audit/version_2845034/checkpoints/epoch=4-step=58590_success.ckpt
  # hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_ptm/0523_ftmarginplus/version_2743441/checkpoints/epoch=3-step=82000-multi_label_acc=91.628.ckpt
  # hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_ptm/0523_ftmarginplus/version_2743441/checkpoints/epoch=2-step=62000-multi_label_acc=92.076.ckpt
# hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_ptm/0523_ftmarginplus/version_2743441/checkpoints/epoch=1-step=28000-multi_label_acc=91.549.ckpt
# hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_ptm/0523_ftmarginplus/version_2743441/checkpoints/epoch=0-step=8000-multi_label_acc=91.218.ckpt
# hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_1013/0317_ema_fix_GB/model_state_epoch_5468.th
# hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_1013/0322_maxlen512_finetune/model_state_epoch_17060.th
  prefix_changes: [ ]
#    - backbone.vision.->backbone.falbert.visual.
    # - backbone.->backbone.falbert.
  download_files: [ ]
#    - hdfs://haruna/home/byte_ecom_govern/user/wangxian/storage/fashionproduct_xl_general_v1->/opt/tiger/easyguard
data:
  train_files: hdfs://harunava/home/byte_magellan_va/user/xuqi/data/feature_audit
  train_size: 17400000
  val_files: hdfs://harunava/home/byte_magellan_va/user/xuqi/data/feature_audit_val
  val_size: 500000
  train_batch_size: 16
  val_batch_size: 32
  num_workers: 2
  text_len: 512
  frame_len: 5
  head_num: 5
  exp: cate_with_ptm
  download_files: [ ]
log_level: INFO
