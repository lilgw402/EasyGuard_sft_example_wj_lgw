trainer:
  default_root_dir: null
  default_hdfs_dir: hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/ansa_demo
  logger: true
  log_every_n_steps: 100
  benchmark: false
  enable_speedmonitor: true
  enable_versions: true
  detect_anomaly: false
  deterministic: true
  accelerator: gpu
  accelerator_kwargs: { }
  precision: fp16
  max_epochs: 5
  max_steps: -1
  limit_train_batches: null
  limit_val_batches: 16
  limit_test_batches: null
  sync_batchnorm: false
  sync_fit_metrics: null
  val_check_interval: [ 1000, 1.0 ]
  accumulate_grad_batches: null
  gradient_clip_val: 1.0
  seed: 42
  summarize_model_depth: 3
  resume_ckpt_path: null
  callbacks: null
  enable_checkpoint: 10
  checkpoint_monitor: val_top1_acc
  checkpoint_mode: max
  dataloader_timeout: -1
  dataloader_retry_limit: 100
  dataloader_retry_persistent_limit: 5
  find_unused_parameters: true
  project_name: null
  experiment_name: null
  enable_trace: false
  reload_dataloaders_every_n_epochs: -1
  strategy: ddp
  enable_qat: false
  qat_kwargs: { }
  optimizer_kwargs:
    optimizer:
      type: torch.optim.AdamW
      params:
        lr: 0.0001
        betas:
          - 0.9
          - 0.999
        eps: 1.0e-06
        weight_decay: 0.01
        correct_bias: true
        correct_bias_eps: false
        bias_correction: true
        adam_w_mode: true
        amsgrad: false
        set_grad_none: true
        momentum: 0.0
        nesterov: false
    scheduler:
      type: torch.optim.lr_scheduler.LinearLR
      total_steps_param_name: total_iters
      warmup_steps_param_name: num_warmup_steps
      params:
        warmup_step_rate: 0.005
        start_factor: 0.3333333333333333
        end_factor: 1.0
        num_cycles: 0.5
        lr_end: 1.0e-07
        power: 1.0
  grad_norm_layers: [ ]
model:
  backbone: fashionproduct-xl-general-v1   # 加载预训练的backbone，通用版fashionproduct-xl-general-v1,更关注高危类目召回则使用fashonproduct-xl-hr-v1
  class_num: 2
  hidden_dim: 768
  optim: AdamW
  learning_rate: 0.0001
  weight_decay: 0.0001
  lr_schedule: linear
  warmup_steps_factor: 1
  low_lr_prefix:
    - backbone
  freeze_prefix: [ ]
  load_pretrained: null
# hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_1013/0322_maxlen512_finetune/model_segtv_17060.th
# hdfs://harunava/home/byte_magellan_va/user/wangxian/projects/tts_all_cat_1013/0317_ema_fix_GB/model_state_epoch_5468.th
  prefix_changes: [ ]
#    - backbone.vision.->backbone.falbert.visual.
#    - backbone.->backbone.falbert.
  download_files: [ ]
data:
  train_files: hdfs://harunava/home/byte_magellan_va/user/wangxian/datasets/ansa_demo/train_img_jsonl
  train_size: 1000000
  val_files: hdfs://harunava/home/byte_magellan_va/user/wangxian/datasets/ansa_demo/val_img_jsonl
  val_size: 22000
  train_batch_size: 64
  val_batch_size: 64
  num_workers: 8
  text_len: 128   # 如使用ptx_tokenizer，应在config.json中修改文本长度
  frame_len: 1
  exp: 0330_finetune_ansa
  download_files: [ ]
log_level: INFO
